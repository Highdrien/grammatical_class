config_metadata: 'Saving time : 12/07/2023, 22:16:01'
name: 'experiment'
save_experiment: true

# data options
data:
    path: 'data'
    language: 'English'
    sequence_length: 10
    pad: '<PAD>'
    unk: '<UNK>'
    sequence_function: 'dummy'
    indexes: [1, 3, 5]
    vocab:
        path: 'dictionary'
        unk_rate: 0.01
        save: false

# model options
model:
    model_name: 'lstm'
    task: 'get_pos'
    num_classes: 19
    lstm:
        lstm_hidd_size_1: 64
        lstm_hidd_size_2: null
        fc_hidd_size: []
        embedding_size: 64
        bidirectional: true
        activation: 'relu'
    bert:
        hidd_size: 100
        pretrained_model_name: 'bert-base-uncased'

# learning options
learning:
    loss: 'crossentropy'
    optimizer: 'adam'
    learning_rate: 0.01
    milesstone: [5, 15]
    gamma: 0.1
    epochs: 10
    batch_size: 2048
    shuffle: true
    drop_last: true
    save_checkpoint: true
