\documentclass[a4paper]{article}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}   % pour les images
\usepackage{hyperref}   % pour les références
\usepackage{amssymb}    % pour les symboles de maths comme \mathbb{R}
\usepackage{mathtools}  % pour rajouter \text dans un environment math
\usepackage{subcaption} % pour les subfigures
\usepackage{todonotes} 
\usepackage{float}
\usepackage[style=ieee]{biblatex}
\addbibresource{ref.bib}
\bibliography{ref.bib}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,   % Couleur des liens internes (table des matières, références)
    citecolor=green,  % Couleur des liens vers les références bibliographiques
    filecolor=magenta, % Couleur des liens vers les fichiers
    urlcolor=blue     % Couleur des liens vers les URL
}


\title{Rapport PSTALN}
\author{Cléa Han, Yanis Labeyrie et Adrien Zabban}
\date{janvier 2024}

\begin{document}

\maketitle
\tableofcontents

\section{Introduction}

Le but de ce projet est de faire un modèle de langage capable de prédire les morphologies des mots d'une phrase
(\textit{morphy}), comme le montre la Figure~\ref{fig: example morphy}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{morphy.png}
    \caption{Tag morphologique d'une phrase Portugaise et sa traduction en Espagnol.
    Image tirée de~\cite{malaviya-etal-2018-neural}}
    \label{fig: example morphy}
\end{figure}    

Nous allons aussi nous demander si est-ce que le fait d'ajouter un prétraitement de la phrase va améliorer
les performances. L'idée de ce prétraitement est de faire prédire le balisage de séquence
prototypique (\textit{pos}) des mots, comme le montre la Figure~\ref{fig: example pos}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{pos.png}
    \caption{La tâche d'étiquetage des parties du discours : la mise en correspondance des mots d'entrée 
    $x_1, x_2,..., x_n$ avec les étiquettes \textit{pos} de sortie $y_1, y_2,..., y_n$.
    Image tirée de~\cite{pos}}
    \label{fig: example pos}
\end{figure} 

\section{Données}

Nous avons utilisé le dataset Universal Dependencies 2.13 ~\cite{11234/1-5287}, qui comporte 146 langues dont l'anglais
et le français. Dans ce projet, nous nous sommes seulement concentrés sur le français.
Le dataset en français contients un ensemble de 47498 phrases, avec 849476 mots, et 76048 mots unique.
Ce dataset possède des phrases, la liste de mots composant ses phrases,
et les \textit{pos} et \textit{morphy} qui sont associés à chacun de ses mots. Au total, nous avons recensé $19$ \textit{pos} et $28$ \textit{morphy} différents.

\subsection{Padding}

Les phrases données au modèle doivent être toutes exactement de la même longueur pendant l'entraînement. 
Notons $K$ la longueur des séquences\footnote{Nous appelons séquence les suites de mots de même taille.}. Nous créons donc des tokens <PAD> pour équilibrer les longueurs des phrases.
Nous avons choisi d'utiliser une méthode naïve pour créer nos séquences qui consiste à couper chaque phrase pour former les séquences
de $K$ mots, et de rajouter si besoin des tokens <PAD> pour terminer la dernière séquence. Nous avons choisi de prendre $K=10$.

\subsection{Gestion des mots inconnus}

Nous avons, avant l'entraînement du modèle, appris un vocabulaire de mots qui fait la correspondance entre les mots et un nombre unique.
Le vocabulaire a été fait seulement sur les mots qui sont dans la base de données d'entraînement. C'est donc pour cela qu'il peut
arriver que des mots de la base de données de validation ou de teste peuvent ne pas être reconnue par le vocabulaire et donc le modèle.
Pour gérer ces mots inconnus, nous avons décidé de leur attribuer le token particulier : <UNK>. Pour que le modèle
apprenne l'embedding de ce mot, il faut alors rajouter artificiellement des mots inconnus dans le corpus d'entraînement. Nous avons
donc, pour chaque mot de ce corpus, remplacé par <UNK> avec une probabilité de $1\%$.


\subsection{Encodage des labels}

Pour encoder les \textit{pos}, nous avons seulement créé une liste de tous les \textit{pos} et avons encodé les \textit{pos} avec leurs indices dans la liste.
Nous avons aussi ajouté le \textit{pos} <PAD> pour que le token de padding soit catégorisé dans ce \textit{pos}.


Pour les \textit{morphy}, cela a été plus compliqué, car un mot peut avoir plusieurs \textit{morphy} associé, avec des valeurs différentes. Nous avons 
décidé d'encoder une suite de \textit{morphy} par une liste de nombre de longueurs $28$ et les éléments sont les indices des possibilités de chaque
\textit{morphy}. Par exemple : le label \textit{Emph=No|Number=Sing|Person=1|PronType=Prs} est encodé par la liste ci-dessous :

[0, 0, 1, 0, 1, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

Comme pour le \textit{pos}, nous avons aussi ajouté un \textit{morphy} pour le padding. Étant donné que le \textit{morphy} qui possède
le plus de possibilités en possède 13, quand nous encodons les labels en one-hot, nous avons un tensor de shape
$(19)$ pour les \textit{pos} et un tensor de shape $(28, 13)$ pour les \textit{morphy}.


\section{Modèle}

\subsection{Architecture des \textit{pos}}

Le modèle, que nous appelons \textit{GET\_POS}, est constitué d'une couche d'embedding pour apprendre les plongements
des mots. Les données passent alors dans une couche LSTM bidirectionnel, puis dans une couche dense (fully connected layers),
avec une sortie à 19 éléments représentant les probabilité de chaque classe \textit{pos}. Nous avons utilisé du 
dropout sur les neurones des couches LSTM et dense, avec un taux d'oublie de $1\%$. Entre ces 3 couches, nous avons 
aussi ajouté la fonciton d'activation ReLU~\cite{DBLP:journals/corr/abs-1803-08375}. Nous avons utilisé la CrossentropyLoss 
comme fonction de coût, l'optimizer Adam~\cite{kingma2014adam}. Ce modèle est représenté sur la Figure~\ref{fig: model getpos}.
Nons avons donc en entrée une matrice de taille $B \times K$, contenant l'indices des mots, où $B$ est la taille du batch.
 Et le modèle retourne un tensor de taille $B \times K \times 19$, contenant les probabilités des \textit{pos} pour chaque mot.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{get_pos.png}
    \caption{Modèle \textit{GET\_POS}}
    \label{fig: model getpos}
\end{figure} 

\subsection{Architecture des \textit{morphy}}

Pour la tâche de prédiction des traits morphologiques, la difficulté est supérieure. En effet pour cette tâche 
il faut pour chaque mot de la phrase prédire à la fois son rôle dans la phrase (Verbe, Nom, ect..) mais aussi 
pour chacune de ses classes prédire des attributs (singulier, pluriel, ...). Nous avons donc crée plusieurs 
architecture différentes que nous allons présenter.

\subsubsection{Modèle \textit{SUPERTAG}}

Le modèle commence par une couche d'embedding pour deux couches de LSTM bidirectionnel. Ensuite on fait passer les données 
dans 3 couches dense caché dont la dernière contients $364$ neurones. Avant que nos données sorte du modèles, elles ont une
taille de $B \times B \times 364$. On \textit{reshape} alors les données pour avoir une sortie de taille 
$B \times B \times 28 \times 13$. La Figure~\ref{fig: model getmorphy} représente ce modèle.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{get_morphy_supertag.png}
    \caption{Modèle \textit{SUPERTAG}}
    \label{fig: model getmorphy}
\end{figure}


\section{Métriques}

Pour pouvoir mesurer les performances de ces modèles nous avons mis en place plusieurs métriques. Pour la prédiction de 
\textit{pos}, nous avons utlisé l'accuracy micro et macro. La première nous donne l'accuracy de la prédiction, et la deuxième
nous donne la moyenne de l'accuracy sur chacune des classes. 

Pour la prédiction de \textit{morphy}, nous avons aussi utilisé l'accuracy micro, et nous avons aussi implémenté une 
metrique qu'on a appelée \textit{all good}, qui fait la moyenne des mots dont la prédiction de tous les \textit{morphy}
sont juste. Si la métrique vaut $0.2$, cela veux dire qu'il y a 1 mots sur 5, qui dont la prédiction est totalement bonne.


\section{Résultats}

\subsection{Résultats pour la prédiction de \textit{pos}}
Nous avons donc lancé un entraînement de notre réseau LSTM-Bidirectionel sur 30 epochs pour le \textit{pos}-tagging et 
nous avons obtenu une accuracy de validation d'environ 90\% ce qui dénote que le réseau à réussi à apprendre 
correctement cette tâche d'étiquetage, comme le montre la figure suivante:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../logs/get_pos_French/acc macro.png}
        \caption{Valeurs de l'accuracy d'entraînement et de validation par epochs.}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../logs/get_pos_French/crossentropy.png}
        \caption{Valeurs de la fonction de coût par epochs.}
    \end{subfigure}
    \caption{Comparaison des récompenses cumulées sur 100 étapes}
\end{figure}

On constate que la valeur de l'accuracy de validation est un peu plus faible que celle d'entraînement, cela 
s'explique par plusieurs facteurs, notamment la difficulté du modèle à généraliser aux nouveaux mots inconnus.

\subsection{Résultats la prédiction des \textit{morphy}}

La tâche de prédiction des traits morphologiques comporte une subtilité: toutes les classes n'ont pas le même 
nombre d'attributs. Par exemple la classe "VERB" a 5 attributs tandis que la classe "NOUN" en a 12. Or, le 
réseau ne
peut pas prédire un vecteur de taille variable. Pour résoudre ce problème, nous avons donc décidé de rajouter 
des attributs fictifs à certaines classes pour que toutes les classes aient le même nombre d'attributs. Pour 
ce faire 
deux solutions sont possibles: soit chacune des sous-couches dense du réseau a le même nombre de neurones, et 
dans ce cas on rajoute des attributs fictifs et inutiles à certaines classe,
soit on définit des couches dense de tailles différentes pour chaque classe égales au noombre d'attributs de 
la classe, mais dans ce cas, il faut rajouter
du padding à la sortie de la couche dense pour que toutes les sorties aient la même taille. Nous avons testé 
les deux méthodes (qu'on appelera $"separate"$ pour la méthode sans padding et $"separate_0"$ pour la méthode 
avec padding après couche et nous avons obtenu de meilleurs résultats avec la deuxième méthode:

Pour la tâche de prédiction des traits morphologiques avec la méthode $separate_0$, nous obtenons les résultats 
suivants: %plot accuracy et crossentropy

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../logs/get_morphy_sep0_French_0/acc micro.png}
        \caption{Valeurs de l'accuracy d'entraînement et de validation par epochs.}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../logs/get_morphy_sep0_French_0/crossentropy.png}
        \caption{Valeurs de la fonction de coût par epochs.}
    \end{subfigure}
    \caption{Courbes d'accuracy et de crossentropy pour la tâche de prédiction des traits morphologiques}
\end{figure}

On mesure également une autre métrique appelée 'allgood' qui mesure le nombre de mots dont tous les attributs 
ont été prédits correctement. On obtient une valeur de allgood de: VALEUR comme le
montre la figure suivante:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\linewidth]{../logs/get_morphy_sep0_French_0/allgood.png}
    \caption{Valeurs de la métrique allgood par epochs.}
\end{figure}


L'entraînement requiert un temps plus long que pour la tâche de \textit{pos}-tagging car il y a beaucoups plus 
d'attributs à prédire.
On obtient une accuracy de validation final de VALEUR, et les courbes montrent que le modèle subit un 
léger sur-apprentissage (comme le montre la valeur de la loss de validation).

Pour la tâche de prédiction des traits morphologiques avec la méthode $separate$, nous obtenons les 
résultats suivants: %plot accuracy et crossentropy

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../logs/get_morphy_separate_French_0/acc micro.png}
        \caption{Valeurs de l'accuracy d'entraînement et de validation par epochs.}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../logs/get_morphy_separate_French_0/crossentropy.png}
        \caption{Valeurs de la fonction de coût par epochs.}
    \end{subfigure}
    \caption{Courbes d'accuracy et de crossentropy pour la tâche de prédiction des traits morphologiques}
\end{figure}

On constate que les résultats sont moins bons que pour la méthode $separate_0$ et que le modèle a besoin de 
plus d'epochs. Cela s'explique par le fait que les attributs fictifs rajoutés aux classes 
pour que toutes les classes aient le même nombre d'attributs sont des attributs inutiles qui n'apportent pas 
d'information au modèle et qui peuvent donc le perturber.





\todo{Mettre ici le graphe d'entraînement}
\todo{Mettre ici des exemples d'inférences (un cas simple, un cas difficile ambigu}

En revanche pour la tâche de prédiction des traits morphologiques les résultats se sont avérés bien inférieurs 
avec une accuracy de validation de seulement 20\%.

\newpage

\printbibliography


\end{document}
