name: experiment
save_experiment: true

# data options
data:
  path: data                  # data path
  language: English           # Language of data
  sequence_length: 10         # length of sequence
  pad: <PAD>                  # pad caracter to make padding
  unk: <UNK>                  # unknow caracter
  sequence_function: dummy    # function to split sentences to sequences
  indexes: [1, 3, 5]          # index of information that will be recupered: 
                                # indexes representation: 
                                # 0: id       1: word    2: lemma   3: pos   4: unk
                                # 5: morphy   6: syntax  7: unk     8: unk   9: unk 
  vocab:
    path: dictionary          # path to save the vocabulary
    unk_rate: 0.01            # rate to replace a knowing word by <UNK>
    save: false               # save the vocabulary or load it from data.voc.path

# model options
model:
  model_name: lstm
  task: get_pos               # choose between get_pos and get_morphy
  num_classes: 19
  hidden_size: 100
  embedding_size: 100

# learning options
learning:
  loss: crossentropy          # loss
  optimizer: adam             # optimizer
  learning_rate: 0.01         # learning rate
  milesstone: [5, 15]         # gradient decay at epoch 5 and 15
  gamma: 0.1                  # learning rate will be multiplicate by 0.1 at epochs 5 and 15
  epochs: 30                  # number of epochs
  batch_size: 1024            # batch size
  shuffle: true
  drop_last: true
  